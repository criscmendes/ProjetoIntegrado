{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport time\nimport pandas as pd\nimport numpy as np\nfrom numpy import array\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.model_selection import learning_curve\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense,RNN,LSTM,Activation,Dropout\nfrom keras.models import Sequential\nfrom tensorflow.compat.v1.keras.layers import CuDNNLSTM\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:06:01.086778Z","iopub.execute_input":"2021-06-14T12:06:01.087183Z","iopub.status.idle":"2021-06-14T12:06:06.580389Z","shell.execute_reply.started":"2021-06-14T12:06:01.087147Z","shell.execute_reply":"2021-06-14T12:06:06.579565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for replicability purposes\ntf.random.set_seed(91195003)\nnp.random.seed(91190530)\n#for an easy reset backend session state\ntf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:06:06.581849Z","iopub.execute_input":"2021-06-14T12:06:06.582177Z","iopub.status.idle":"2021-06-14T12:06:06.599922Z","shell.execute_reply.started":"2021-06-14T12:06:06.582142Z","shell.execute_reply":"2021-06-14T12:06:06.599053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv(\"../input/dataset/newsfeatures_withlabels.csv\")\ndf2 = pd.read_csv(\"../input/category/topic_cats.csv\")\ndf3 = pd.read_csv(\"../input/titleef-v2/items_title_EFv2.csv\")\n\n# descomentar para Métrica 2\n#dfM2 = pd.read_csv(\"../input/metricas/news_M2.csv\")\n#dfM2 = dfM2[['news_id', 'Toxic_Class']]\n\n# descomentar para Métrica 3\n#dfM3 = pd.read_csv(\"../input/metricas/news_M3.csv\")\n#dfM3 = dfM3[['news_id', 'Toxic_Class']]\n\n# descomentar para Métrica 4\n#dfM4 = pd.read_csv(\"../input/metricas/news_M4.csv\")\n#dfM4 = dfM4[['news_id', 'Toxic_Class']]\n\n# descomentar para Métrica 2\n#df1 = pd.merge(df1.drop(columns=['Toxic_Class']), dfM2, on='news_id', how='inner')\n\n# descomentar para Métrica 3\n#df1 = pd.merge(df1.drop(columns=['Toxic_Class']), dfM3, on='news_id', how='inner')\n\n# descomentar para Métrica 4\n#df1 = pd.merge(df1.drop(columns=['Toxic_Class']), dfM4, on='news_id', how='inner')\n\ndfaux = pd.merge(df1, df2, on = 'news_id', how='inner')\ndf = pd.merge(dfaux, df3, on = 'news_id', how='inner')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:48:50.847312Z","iopub.execute_input":"2021-06-14T12:48:50.847635Z","iopub.status.idle":"2021-06-14T12:48:51.011565Z","shell.execute_reply.started":"2021-06-14T12:48:50.847603Z","shell.execute_reply":"2021-06-14T12:48:51.010645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare Data\n'''\nBase + numero comentários + categoria\n\"^title_|time_of_day|newsoutlet_country|newsoutlet_name|num_comments_article|TC_\"\n\nBase + v1 + entidades corpo\n\"^title_|time_of_day|newsoutlet_country|newsoutlet_name|^freq_|text_\"\n\nBase + Keywords + v2\n\"^title_|time_of_day|newsoutlet_country|newsoutlet_name|[0-9]|noun_freq_\"\n'''\n\ndX = df.filter(regex=(\"^title_|time_of_day|newsoutlet_country|newsoutlet_name|[0-9]|noun_freq_\")).copy()\ndX","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:48:51.922834Z","iopub.execute_input":"2021-06-14T12:48:51.923163Z","iopub.status.idle":"2021-06-14T12:48:52.018767Z","shell.execute_reply.started":"2021-06-14T12:48:51.923133Z","shell.execute_reply":"2021-06-14T12:48:52.017909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split data into training and validation sets\ndef split_data(training, perc=20):\n  train_idx = np.arange(0, int(len(training)*(100-perc)/100))\n  val_idx = np.arange(int(len(training)*(100-perc)/100+1), len(training))\n  return train_idx, val_idx","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:49:05.765453Z","iopub.execute_input":"2021-06-14T12:49:05.765805Z","iopub.status.idle":"2021-06-14T12:49:05.772025Z","shell.execute_reply.started":"2021-06-14T12:49:05.765772Z","shell.execute_reply":"2021-06-14T12:49:05.770829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_normalization(dataX, norm_range=(0, 1)):\n    scaler = MinMaxScaler(feature_range=norm_range)\n    \n    for c in dataX.columns:\n        dataX[[c]] = scaler.fit_transform(dataX[[c]])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:49:06.021418Z","iopub.execute_input":"2021-06-14T12:49:06.021843Z","iopub.status.idle":"2021-06-14T12:49:06.029563Z","shell.execute_reply.started":"2021-06-14T12:49:06.021802Z","shell.execute_reply":"2021-06-14T12:49:06.028836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Vizualizing Learning Curves \ndef plot_learning_curves(data, approach):\n\n  plt.figure(figsize=(8,6))\n  if approach == 'history':\n    plt.title('Model train vs val loss per Training Split')\n    plt.ylabel('Training RMSE (Normalized)')\n    plt.xlabel('Epoch')\n    for hist, i in zip(data, range(len(data))):\n      plt.subplot(n_splits,1,i+1)\n      plt.plot(hist.epoch, hist.history['loss'])\n      plt.plot(hist.epoch, hist.history['val_loss'])\n      plt.xlim([0, max(hist.epoch)])\n      plt.legend(['Training split ' + str(i+1) + '- train loss', 'Training split ' + str(i+1) + '- val loss' ])\n    plt.show()\n  elif approach == 'loss':\n    plt.figure(figsize=(6,3))\n    plt.plot(range(len(data)),data)\n    plt.title('RMSE value per K Fold')\n    plt.ylabel('Evaluation RMSE')\n    plt.xlabel('K Folds')\n    plt.xlim([0,2])\n    plt.ylim([0,(np.amax(data)+2)])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:49:06.206022Z","iopub.execute_input":"2021-06-14T12:49:06.206585Z","iopub.status.idle":"2021-06-14T12:49:06.217766Z","shell.execute_reply.started":"2021-06-14T12:49:06.206543Z","shell.execute_reply":"2021-06-14T12:49:06.217016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(multivariate, h_layers = 2, h_neurons = 64, activation = 'sigmoid', dropout_rate = 0.5, deep_dense = False):\n  model = tf.keras.models.Sequential()\n  for i in range(h_layers):\n    if i == 0:\n      if i+1 == h_layers:\n        model.add(CuDNNLSTM(h_neurons, return_sequences = False, input_shape = (multivariate, 1)))\n      else:\n        model.add(CuDNNLSTM(int(h_neurons/2), return_sequences = True, input_shape = (multivariate, 1)))\n        model.add(tf.keras.layers.Dropout(dropout_rate))\n    elif i+1 == h_layers:\n      model.add(CuDNNLSTM(h_neurons*2, return_sequences = False))\n    else:\n      model.add(CuDNNLSTM(h_neurons, return_sequences = True))\n      model.add(tf.keras.layers.Dropout(dropout_rate))\n  \n  model.add(tf.keras.layers.Dense(h_neurons, activation))\n  model.add(tf.keras.layers.Dropout(dropout_rate))\n\n  if deep_dense == True:\n    model.add(tf.keras.layers.Dense(int(h_neurons/2), activation))\n    model.add(tf.keras.layers.Dropout(dropout_rate))\n  model.add(tf.keras.layers.Dense(1, activation='linear'))\n  model.compile(loss = 'binary_crossentropy', optimizer = tf.keras.optimizers.Adam(), metrics = ['accuracy'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:49:06.449757Z","iopub.execute_input":"2021-06-14T12:49:06.450239Z","iopub.status.idle":"2021-06-14T12:49:06.462172Z","shell.execute_reply.started":"2021-06-14T12:49:06.450203Z","shell.execute_reply":"2021-06-14T12:49:06.461404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compiling and fit the model\ndef compile_and_fit(model, epochs, batch_size):\n  \n  callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n      #saving in Keras HDF5 (or h5), a binary data format\n      filepath='ckpt/my_model_{epoch}_{val_loss:.3f}.hdf5', #path where to save the model\n      save_best_only=True, #overwrite the current checkpoint if and only if\n      monitor='val_loss', #the val_loss score has improved\n      save_weights_only=False, #if True, only the weights are saved\n      verbose=1), #verbosity mode\n    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=20, min_delta=0.00001),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=50, min_lr=0.00005, cooldown=5)\n  ]\n\n  #fit\n  hist_list = list()\n  loss_list = list()\n  \n    \n  #K Folds Validation\n  kfold = StratifiedKFold(n_splits, shuffle=True, random_state=np.random.seed(seed))\n  for train_idx, test_idx in kfold.split(dataX, datay):\n    train_idx, val_idx = split_data(train_idx, perc=10) #further split into training and validation sets\n    \n    #build data\n    X_train, y_train = dataX[train_idx], datay[train_idx] \n    X_val, y_val = dataX[val_idx], datay[val_idx] \n    X_test, y_test = dataX[test_idx], datay[test_idx]\n    print(X_train.shape)\n    \n    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n    X_test = np.reshape(X_test, (X_test.shape[0], X_train.shape[1], 1))\n    X_val = np.reshape(X_val, (X_val.shape[0], X_train.shape[1], 1))\n                        \n    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n                        epochs=epochs, batch_size=batch_size, shuffle=False, callbacks=callbacks)\n    \n    metrics = model.evaluate(X_test, y_test)\n    \n    hist_list.append(history)\n    loss_list.append(metrics[1])\n\n  print(f'ACCURACY LIST {loss_list} MEAN: {np.mean(loss_list)}')\n\n\n  plot_learning_curves(hist_list, approach='history')\n  plot_learning_curves(loss_list, approach='loss')\n  \n  return model, hist_list, loss_list, history","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:49:06.82557Z","iopub.execute_input":"2021-06-14T12:49:06.825886Z","iopub.status.idle":"2021-06-14T12:49:06.837147Z","shell.execute_reply.started":"2021-06-14T12:49:06.825858Z","shell.execute_reply":"2021-06-14T12:49:06.836184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Main Execution\nmultivariate = 1064 #number of features used by the model\nseed = 7\nn_splits = 7 \nepochs = 100\nbatch_size = 64 \n\nscaler = data_normalization(dX)\ndataX=np.array(dX)\ndatay=np.array(d['Toxic_Class'])\n\n#fitting the model\nstartTime = time.time()\n\nmodel = build_model(multivariate, h_layers = 3, h_neurons = 128, activation = 'sigmoid', dropout_rate = 0.2, deep_dense = False)\nmodel.summary()\nmodel, hist_list, loss_list, history = compile_and_fit(model, epochs, batch_size)\n\nfinishTime = time.time() - startTime\nprint('Execution Time:', finishTime)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:49:07.393355Z","iopub.execute_input":"2021-06-14T12:49:07.393637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtest=np.random.rand(1,1083)\nXtest","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:46:11.056947Z","iopub.execute_input":"2021-06-13T18:46:11.057267Z","iopub.status.idle":"2021-06-13T18:46:11.063972Z","shell.execute_reply.started":"2021-06-13T18:46:11.057237Z","shell.execute_reply":"2021-06-13T18:46:11.062841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtest = np.reshape(Xtest, (Xtest.shape[0], Xtest.shape[1], 1))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T14:03:38.573313Z","iopub.execute_input":"2021-06-13T14:03:38.573631Z","iopub.status.idle":"2021-06-13T14:03:38.578392Z","shell.execute_reply.started":"2021-06-13T14:03:38.573599Z","shell.execute_reply":"2021-06-13T14:03:38.577322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred = model.predict(Xtest)\n#score = model.evaluate(X_test, y_test,verbose=1)\n#print(score)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T14:03:39.643652Z","iopub.execute_input":"2021-06-13T14:03:39.644154Z","iopub.status.idle":"2021-06-13T14:03:39.648162Z","shell.execute_reply.started":"2021-06-13T14:03:39.644102Z","shell.execute_reply":"2021-06-13T14:03:39.646925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict_classes(Xtest)\nprint(\"X=%s, Predicted=%s\" % (Xtest[0], y_pred[0]))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T14:03:40.573307Z","iopub.execute_input":"2021-06-13T14:03:40.57362Z","iopub.status.idle":"2021-06-13T14:03:40.855148Z","shell.execute_reply.started":"2021-06-13T14:03:40.57359Z","shell.execute_reply":"2021-06-13T14:03:40.854256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}